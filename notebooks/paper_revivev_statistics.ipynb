{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../tools')\n",
    "\n",
    "import os\n",
    "\n",
    "from extract_features_from_lyric import load_full_lyric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected lang = so\n",
      "Detected lang = it\n",
      "Song ML1056 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML1068.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1098.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1159.json lyric is empty\n",
      "For ..\\..\\database\\lyrics\\ML1159.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics\\ML1159.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics\\ML1230.json lyric is empty\n",
      "For ..\\..\\database\\lyrics\\ML1230.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics\\ML1230.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics\\ML1291.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1333.json there is no language info in dataset\n",
      "Detected lang = de\n",
      "For ..\\..\\database\\lyrics\\ML1336.json lyric is empty\n",
      "For ..\\..\\database\\lyrics\\ML1336.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics\\ML1336.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics\\ML1349.json lyric is empty\n",
      "For ..\\..\\database\\lyrics\\ML1349.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics\\ML1349.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics\\ML136.json there is no language info in dataset\n",
      "Detected lang = cs\n",
      "For ..\\..\\database\\lyrics\\ML137.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1434.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1561.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1637.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Song ML1697 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML1719.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1765.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1774.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Song ML1816 is duplicated. \n",
      "Detected lang = pt\n",
      "Song ML186 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML1864.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1869.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1894.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1911.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1918.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1941.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Song ML1945 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML1948.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML1953.json there is no language info in dataset\n",
      "Detected lang = de\n",
      "Song ML1957 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML1960.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML259.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Song ML291 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML299.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Detected lang = so\n",
      "Song ML312 is duplicated. \n",
      "Detected lang = it\n",
      "For ..\\..\\database\\lyrics\\ML379.json lyric is empty\n",
      "For ..\\..\\database\\lyrics\\ML379.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics\\ML379.json is instrumental\n",
      "\n",
      "Detected lang = so\n",
      "For ..\\..\\database\\lyrics\\ML417.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML497.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML589.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML595.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Song ML613 is duplicated. \n",
      "Detected lang = en\n",
      "Song ML629 is duplicated. \n",
      "For ..\\..\\database\\lyrics\\ML687.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Detected lang = sw\n",
      "For ..\\..\\database\\lyrics\\ML792.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics\\ML999.json there is no language info in dataset\n",
      "Detected lang = en\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join('..', '..', 'database', 'lyrics')\n",
    "database_path = os.path.join('..', 'database', 'MoodyLyrics4Q_cleaned_split.csv')\n",
    "\n",
    "dataset = load_full_lyric_dataset(dataset_path, database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>title</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>instrumental</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ML1</th>\n",
       "      <td>happy</td>\n",
       "      <td>I Want Your Sex</td>\n",
       "      <td>I Want Your Sex Lyrics[From a PSA recorded for...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML10</th>\n",
       "      <td>happy</td>\n",
       "      <td>Heart of Glass</td>\n",
       "      <td>Heart of Glass Lyrics[Verse 1]\\nOnce I had a l...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML100</th>\n",
       "      <td>happy</td>\n",
       "      <td>Crazy Little Thing Called Love</td>\n",
       "      <td>Crazy Little Thing Called Love Lyrics[Intro]\\n...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML1000</th>\n",
       "      <td>happy</td>\n",
       "      <td>Almost</td>\n",
       "      <td>Almost Lyrics[Verse 1]\\nI almost got drunk at ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML1001</th>\n",
       "      <td>happy</td>\n",
       "      <td>Glow</td>\n",
       "      <td>Glow Lyrics[Verse 1]\\nI never thought that you...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mood                           title  \\\n",
       "ML1     happy                 I Want Your Sex   \n",
       "ML10    happy                  Heart of Glass   \n",
       "ML100   happy  Crazy Little Thing Called Love   \n",
       "ML1000  happy                          Almost   \n",
       "ML1001  happy                            Glow   \n",
       "\n",
       "                                                    lyric language  \\\n",
       "ML1     I Want Your Sex Lyrics[From a PSA recorded for...       en   \n",
       "ML10    Heart of Glass Lyrics[Verse 1]\\nOnce I had a l...       en   \n",
       "ML100   Crazy Little Thing Called Love Lyrics[Intro]\\n...       en   \n",
       "ML1000  Almost Lyrics[Verse 1]\\nI almost got drunk at ...       en   \n",
       "ML1001  Glow Lyrics[Verse 1]\\nI never thought that you...       en   \n",
       "\n",
       "        instrumental  split  \n",
       "ML1            False  train  \n",
       "ML10           False  train  \n",
       "ML100          False  train  \n",
       "ML1000         False  train  \n",
       "ML1001         False  train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = dataset[dataset['mood'] == 'happy']\n",
    "sad = dataset[dataset['mood'] == 'sad']\n",
    "angry = dataset[dataset['mood'] == 'angry']\n",
    "relaxed = dataset[dataset['mood'] == 'relaxed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    350\n",
       "test      75\n",
       "val       75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy.value_counts('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dataset = dataset[dataset['language'] == 'en']\n",
    "\n",
    "en_happy = en_dataset[en_dataset['mood'] == 'happy']\n",
    "en_sad = en_dataset[en_dataset['mood'] == 'sad']\n",
    "en_angry = en_dataset[en_dataset['mood'] == 'angry']\n",
    "en_relaxed = en_dataset[en_dataset['mood'] == 'relaxed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    331\n",
       "test      72\n",
       "val       68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_happy.value_counts('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ML1       I Want Your Sex Lyrics[From a PSA recorded for...\n",
       "ML10      Heart of Glass Lyrics[Verse 1]\\nOnce I had a l...\n",
       "ML100     Crazy Little Thing Called Love Lyrics[Intro]\\n...\n",
       "ML1000    Almost Lyrics[Verse 1]\\nI almost got drunk at ...\n",
       "ML1001    Glow Lyrics[Verse 1]\\nI never thought that you...\n",
       "Name: lyric, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_happy['lyric'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyric(lyric, tokenizer):\n",
    "    return tokenizer(lyric, return_tensors='pt')\n",
    "\n",
    "def get_statistics(num_tokens):\n",
    "    print(f'Mean: {np.round(np.mean(num_tokens), 2)}')\n",
    "    print(f'Max : {np.max(num_tokens)}')\n",
    "    print(f'Min : {np.min(num_tokens)}')\n",
    "    print(f'Std : {np.round(np.std(num_tokens), 2)}')\n",
    "\n",
    "def count_tokens(lyrics, tokenizer):\n",
    "    return [len(tokenizer(lyric)['input_ids']) for lyric in lyrics]\n",
    "\n",
    "def get_statistics_for_category(dataset, tokenizer):\n",
    "    num_tokens = count_tokens(dataset['lyric'], tokenizer)\n",
    "    get_statistics(num_tokens)\n",
    "\n",
    "def get_all_statistics(tokenizer):\n",
    "    print('Happy')\n",
    "    get_statistics_for_category(en_happy, tokenizer)\n",
    "\n",
    "    print('Angry')\n",
    "    get_statistics_for_category(en_angry, tokenizer)\n",
    "\n",
    "    print('Sad')\n",
    "    get_statistics_for_category(en_sad, tokenizer)\n",
    "\n",
    "    print('Relaxed')\n",
    "    get_statistics_for_category(en_relaxed, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n",
      "Mean: 500.87\n",
      "Max : 2182\n",
      "Min : 31\n",
      "Std : 283.03\n",
      "Angry\n",
      "Mean: 451.25\n",
      "Max : 1890\n",
      "Min : 78\n",
      "Std : 295.35\n",
      "Sad\n",
      "Mean: 287.08\n",
      "Max : 1555\n",
      "Min : 29\n",
      "Std : 169.91\n",
      "Relaxed\n",
      "Mean: 288.19\n",
      "Max : 1324\n",
      "Min : 20\n",
      "Std : 180.38\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "get_all_statistics(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp39-cp39-win_amd64.whl (798 kB)\n",
      "                                              0.0/798.7 kB ? eta -:--:--\n",
      "     -                                     41.0/798.7 kB 653.6 kB/s eta 0:00:02\n",
      "     --------                               174.1/798.7 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------                    419.8/798.7 kB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------------  788.5/798.7 kB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 798.7/798.7 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from tiktoken) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\janto\\anaconda3\\envs\\emotions\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "def split_into_words(lyric):\n",
    "    return lyric.split()\n",
    "\n",
    "def get_statistics(num_words):\n",
    "    print(f'Mean: {np.round(np.mean(num_words), 2)}')\n",
    "    print(f'Max : {np.max(num_words)}')\n",
    "    print(f'Min : {np.min(num_words)}')\n",
    "    print(f'Std : {np.round(np.std(num_words), 2)}')\n",
    "\n",
    "def count_words(lyrics, tokenizer):\n",
    "    return [len(tokenizer(lyric)['input_ids']) for lyric in lyrics]\n",
    "\n",
    "def get_statistics_for_category(dataset, tokenizer):\n",
    "    num_tokens = count_tokens(dataset['lyric'], tokenizer)\n",
    "    get_statistics(num_tokens)\n",
    "\n",
    "def get_all_statistics(tokenizer):\n",
    "    print('Happy')\n",
    "    get_statistics_for_category(en_happy, tokenizer)\n",
    "\n",
    "    print('Angry')\n",
    "    get_statistics_for_category(en_angry, tokenizer)\n",
    "\n",
    "    print('Sad')\n",
    "    get_statistics_for_category(en_sad, tokenizer)\n",
    "\n",
    "    print('Relaxed')\n",
    "    get_statistics_for_category(en_relaxed, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
