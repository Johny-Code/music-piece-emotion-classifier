{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        language = None\n",
    "    print(f\"Detected lang = {language}\")\n",
    "\n",
    "    return language\n",
    "\n",
    "INSTRUMENTAL_COMMENT = \"This song is an instrumental\"\n",
    "\n",
    "def load_lyric_dataset(input_path):\n",
    "\n",
    "    rows = list()\n",
    "    ids = list()\n",
    "\n",
    "    lyric_files = [os.path.join(input_path, pos_json) for pos_json in os.listdir(input_path) if pos_json.endswith('.json')]\n",
    "\n",
    "    for file_path in lyric_files:\n",
    "        with open(file_path) as f:\n",
    "            song_info = json.load(f)\n",
    "\n",
    "        try:\n",
    "            id = song_info['id']\n",
    "            id = id.replace(\"ML\", \"\")\n",
    "            id = int(id)\n",
    "        except:\n",
    "            id = None\n",
    "            print(f\"For {file_path} there is no id\")\n",
    "\n",
    "        try:\n",
    "            mood = song_info['mood']\n",
    "        except:\n",
    "            mood = None\n",
    "            print(f\"For {file_path} there is no mood\")\n",
    "\n",
    "        try:\n",
    "            title = song_info['title']\n",
    "        except:\n",
    "            title = None\n",
    "            print(f\"For {file_path} there is no title\")\n",
    "\n",
    "        try:\n",
    "            lyric = song_info['song']['lyrics']\n",
    "            if lyric == '': \n",
    "                print(f\"For {file_path} lyric is empty\")\n",
    "        except:\n",
    "            lyric = None\n",
    "            print(f\"For {file_path} there is no lyrics\")\n",
    "        \n",
    "        try:\n",
    "            language = song_info['song']['language']\n",
    "            if language == None: language = detect_language(lyric)\n",
    "        except:\n",
    "            print(f\"For {file_path} there is no language info in dataset\")\n",
    "            language = detect_language(lyric)\n",
    "            \n",
    "\n",
    "        try:\n",
    "            comment = song_info['song']['//coment']\n",
    "            if comment == INSTRUMENTAL_COMMENT:\n",
    "                instrumental = True\n",
    "                print(f\"For {file_path} is instrumental\\n\")\n",
    "            else:\n",
    "                instrumental = False\n",
    "        except:\n",
    "            instrumental = False\n",
    "\n",
    "        row = (mood, title, lyric, language, instrumental)\n",
    "        \n",
    "        rows.append(row)\n",
    "        ids.append(id)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['mood', 'title', 'lyric', 'language', 'instrumental'], index=ids)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_en_dataset(path):\n",
    "\n",
    "    dataset = load_lyric_dataset(path) \n",
    "\n",
    "    dataset = dataset.loc[dataset['language'] == \"en\"]\n",
    "    en_dataset = dataset.loc[dataset['instrumental'] == False]\n",
    "    \n",
    "    return en_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected lang = so\n",
      "Detected lang = it\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML136.json there is no language info in dataset\n",
      "Detected lang = cs\n",
      "Detected lang = pt\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1948.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Detected lang = so\n",
      "Detected lang = it\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json is instrumental\n",
      "\n",
      "Detected lang = so\n",
      "Detected lang = en\n",
      "Detected lang = sw\n"
     ]
    }
   ],
   "source": [
    "input_path = os.path.join('..', '..', 'database', 'lyrics_cleaned')\n",
    "\n",
    "en_dataset = load_en_dataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>title</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1882</td>\n",
       "      <td>1882</td>\n",
       "      <td>1882</td>\n",
       "      <td>1882</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>1863</td>\n",
       "      <td>1882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>angry</td>\n",
       "      <td>Fire</td>\n",
       "      <td>I Want Your Sex Lyrics[From a PSA recorded for...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>490</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1882</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mood title                                              lyric  \\\n",
       "count    1882  1882                                               1882   \n",
       "unique      4  1863                                               1882   \n",
       "top     angry  Fire  I Want Your Sex Lyrics[From a PSA recorded for...   \n",
       "freq      490     3                                                  1   \n",
       "\n",
       "       language instrumental  \n",
       "count      1882         1882  \n",
       "unique        1            1  \n",
       "top          en        False  \n",
       "freq       1882         1882  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>title</th>\n",
       "      <th>lyric</th>\n",
       "      <th>language</th>\n",
       "      <th>instrumental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mood, title, lyric, language, instrumental]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicated english lyrics\n",
    "df2 = en_dataset[en_dataset['lyric'].duplicated()]\n",
    "df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no duplicated rows - good news!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyric(lyric, title):\n",
    "    \n",
    "    #remove title and genius annotation\n",
    "    lyric = re.sub(\".+Lyrics.+\\]\", '',  lyric)\n",
    "\n",
    "    #removing title (exception detected)\n",
    "    lyric = re.sub(f'{title}.+Lyrics', '', lyric)\n",
    "\n",
    "    #remove exery anotation like [Verse 1], [Chorus], [Bridge], [Part 1] etc.\n",
    "    lyric = re.sub('\\[.+\\]', '', lyric)\n",
    "\n",
    "    #remove every ********* in the lyric\n",
    "    lyric = re.sub('\\*.+\\*', '', lyric)\n",
    "\n",
    "    #remove Genius anotation \"You might also like\"\n",
    "    lyric = re.sub('You might also like', '', lyric)\n",
    "\n",
    "    #remove Embed exist in every lyric in the end\n",
    "    if lyric[-5:] == 'Embed':\n",
    "        lyric = re.sub('Embed', '', lyric)\n",
    "        if lyric[-1:].isdigit():\n",
    "            lyric = re.sub('\\d', '', lyric)\n",
    "\n",
    "    return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lyric in dataset\n",
    "# en_dataset\n",
    "\n",
    "# iterate through the dataframe and clean the lyric then update the lyric column\n",
    "\n",
    "for index, row in en_dataset.iterrows():\n",
    "    lyric = row['lyric']\n",
    "    title = row['title']\n",
    "    en_dataset.at[index, 'lyric'] = clean_lyric(lyric, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "emotion_labels_dict = {'happy': 0, 'sad': 1, 'relaxed': 2, 'angry': 3}\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# The language model we are using has some issues with stop words.\n",
    "# Basically we need to grab stopwords from the 'en' language model\n",
    "# and add them back to the model we are using.\n",
    "# https://github.com/explosion/spaCy/issues/922\n",
    "nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    tks = list(filter(lambda tk: not tk.is_stop, doc))\n",
    "    return spacy.tokens.Doc(nlp.vocab, words=[tk.text for tk in tks])\n",
    "\n",
    "\n",
    "def load_dataset(df):\n",
    "    rows = list()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        mood = emotion_labels_dict[row['mood']]\n",
    "        \n",
    "        lyric = row['lyric']\n",
    "        doc = nlp(lyric)\n",
    "        doc = remove_stopwords(doc)\n",
    "                               \n",
    "        if len(doc.vector) == 300:\n",
    "            rows.append((mood, doc.vector, doc.vector_norm)) \n",
    "\n",
    "    return pd.DataFrame(rows, columns=['Mood', 'Vector', 'Vector_Norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(en_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect = dataset['Vector'].to_numpy().T\n",
    "X_vect = np.array([np.array(x) for x in X_vect])\n",
    "\n",
    "y = dataset['Mood'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=10: 0.56 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = SVC(kernel= 'linear' , C= 0.01)\n",
    "\n",
    "k = 10\n",
    "scores = cross_val_score(clf, X_vect, y, cv=k)\n",
    "print(f\"Accuracy for k={k}: {round(scores.mean(), 2)} (+/- {round((scores.std() * 1.96), 2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the set of parameters we want to test on\n",
    "params = [\n",
    "    { 'kernel': ['linear'], 'C': [ 0.01, 0.05, 1, 10, 100 ]},\n",
    "    { 'kernel': ['rbf', 'sigmoid'], 'C': [ 0.01, 0.05, 0.1, 0.3, 0.8, 1, 3, 10, 50, 100, 150, 200 ] }\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(SVC(), params, cv=10, n_jobs=-1, verbose=False)\n",
    "gs.fit(X_vect, y) \n",
    "\n",
    "svm_best = gs.best_estimator_\n",
    "best_params = gs.best_params_\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=10: 0.56 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_best, X_vect, y, cv=10)\n",
    "print(f\"Accuracy for k={k}: {round(scores.mean(), 2)} (+/- {round((scores.std() * 1.96), 2)})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considered features:\n",
    "according to: https://github.com/sgiammy/emotion-patterns-in-music-playlists\n",
    "\n",
    "<ul>\n",
    "    <li>**Title_vector**</li>\n",
    "    <li>**Lyric_vector**</li>\n",
    "    <li>**%Rhymes**:<br> defined as the percentage of the number of rhymes over the number of total lines. A rhyme is defined as a rhyme between two following lines.</li>\n",
    "    <li>**%Past_tense_verbs**:<br> defined as the the percentage of the number of past tense verbs over the total number of verbs.</li>\n",
    "    <li>**%Present_tense_verbs**:<br>  defined as the the percentage of the number of present tense verbs over the total number of verbs.</li>\n",
    "    <li>**%Future_tense_verbs**:<br>  defined as the the percentage of the number of future tense verbs over the total number of verbs, where future is just will + base form.</li>\n",
    "    <li>**%ADJ**:<br> Percentage of adjectives over the total number of words.</li>\n",
    "    <li>**%ADP**:<br> Percentage of adpositions (e.g. in, to, during) over the total number of words.</li>\n",
    "    <li>**%ADV**:<br> Percentage of adverbs (e.g. very, tomorrow, down, where, there) over the total number of words.</li>\n",
    "    <li>**%AUX**:<br> Percentage of auxiliaries (e.g. is, has (done), will (do), should (do)) over the total number of words.</li>\n",
    "    <li>**%INTJ**:<br> Percentage of interjections (e.g. psst, ouch, bravo, hello) over the total number of words.</li>\n",
    "    <li>**%NOUN**:<br> Percentage of nouns over the total number of words.</li>\n",
    "    <li>**%NUM**:<br> Percentage of numerals over the total number of words.</li>\n",
    "    <li>**%PRON**:<br> Percentage of pronouns (e.g. I, you, he, she, myself, themselves, somebody,...) over the total number of words.</li> \n",
    "    <li>**%PROPN**:<br> Percentage of proper nouns (e.g. Mary, John) over the total number of words.</li>\n",
    "    <li>**%PUNCT**:<br> Percentage of puntuctuation (e.g. ., (, ), ?) over the total number of words.</li>\n",
    "    <li>**%VERB**:<br> Percentage of verbs over the total number of words.</li>\n",
    "    <li>**Selfish_degree**:<br> Percentage of 'I' pronouns over the total number of pronouns</li>\n",
    "    <li>**%Echoism**:<br> Percentage of echoism over the total number of words, where an echoism is either a sequence of two subsequent repeated words or the repetition of a vowel in a word. </li>\n",
    "    <li>**%Duplicates**:<br> Percentage of duplicate words over the total number of words</li>\n",
    "    <li>**isTitleInLyric**:<br> Boolean, true if the title string is also a substring of the lyric</li>\n",
    "    <li>**sentiment**:<br> Sentiment between -1 and 1</li>\n",
    "    <li>**subjectivity degree**:<br> Degree of subjectivity of the text</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected lang = so\n",
      "Detected lang = it\n",
      "Detected lang = en\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1159.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1230.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1336.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1349.json is instrumental\n",
      "\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML136.json there is no language info in dataset\n",
      "Detected lang = cs\n",
      "Detected lang = pt\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML1948.json there is no language info in dataset\n",
      "Detected lang = en\n",
      "Detected lang = so\n",
      "Detected lang = it\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json lyric is empty\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json there is no language info in dataset\n",
      "No features in text.\n",
      "Detected lang = None\n",
      "For ..\\..\\database\\lyrics_cleaned\\ML379.json is instrumental\n",
      "\n",
      "Detected lang = so\n",
      "Detected lang = en\n",
      "Detected lang = sw\n"
     ]
    }
   ],
   "source": [
    "input_path = os.path.join('..', '..', 'database', 'lyrics_cleaned')\n",
    "\n",
    "en_dataset = load_en_dataset(input_path)\n",
    "\n",
    "for index, row in en_dataset.iterrows():\n",
    "    lyric = row['lyric']\n",
    "    title = row['title']\n",
    "    en_dataset.at[index, 'lyric'] = clean_lyric(lyric, title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
